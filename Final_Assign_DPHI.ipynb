{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-06T19:08:58.748914Z","iopub.execute_input":"2022-03-06T19:08:58.749906Z","iopub.status.idle":"2022-03-06T19:08:58.761511Z","shell.execute_reply.started":"2022-03-06T19:08:58.749863Z","shell.execute_reply":"2022-03-06T19:08:58.760809Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Importing basic dependencies and libraries.\n\n- Numpy as we will work with vectors and arrays\n- Pandas to build de dataframes\n- Matplotlib for some visualizations\n- Metrics for evaluation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:08:58.763302Z","iopub.execute_input":"2022-03-06T19:08:58.763594Z","iopub.status.idle":"2022-03-06T19:08:59.825660Z","shell.execute_reply.started":"2022-03-06T19:08:58.763553Z","shell.execute_reply":"2022-03-06T19:08:59.824608Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading and viewing dataset\n\n__we have 2 datasets: train and test (.csv)__\n\nSince this will be an supervised machine learning workflow the train dataset must have the labels:\n   - 1 = is sarcastic\n   - 0 = not sarcastic","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/headlines-dataset/Assignment_Train_Dataset.csv')\nprint(df.shape) # 44262 rows and 2 columns\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:08:59.826999Z","iopub.execute_input":"2022-03-06T19:08:59.827250Z","iopub.status.idle":"2022-03-06T19:08:59.961286Z","shell.execute_reply.started":"2022-03-06T19:08:59.827218Z","shell.execute_reply":"2022-03-06T19:08:59.960272Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Observing dataframe\n\nWe have a balance of 54% to 46% between \"is_sarcastic\" and \"not sarcastic\" (represented by 1 and 0, respectively)","metadata":{}},{"cell_type":"code","source":"df['is_sarcastic'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:08:59.962985Z","iopub.execute_input":"2022-03-06T19:08:59.963277Z","iopub.status.idle":"2022-03-06T19:08:59.979458Z","shell.execute_reply.started":"2022-03-06T19:08:59.963237Z","shell.execute_reply":"2022-03-06T19:08:59.978450Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(\"Visualizing ratio is sacarstic vs not sarcastic:\\n\")\ncount_Class = pd.value_counts(df['is_sarcastic'], sort=True)\ncount_Class.plot(kind = 'pie',labels=['not_sarc','sarc'], autopct='%1.0f%%,')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:08:59.981876Z","iopub.execute_input":"2022-03-06T19:08:59.982437Z","iopub.status.idle":"2022-03-06T19:09:00.159322Z","shell.execute_reply.started":"2022-03-06T19:08:59.982405Z","shell.execute_reply":"2022-03-06T19:09:00.158300Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Splitting data into train and test datasets.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df[['headline']], df['is_sarcastic'],\n                                                    test_size=0.33,\n                                                    random_state=42)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.160924Z","iopub.execute_input":"2022-03-06T19:09:00.161337Z","iopub.status.idle":"2022-03-06T19:09:00.208823Z","shell.execute_reply.started":"2022-03-06T19:09:00.161287Z","shell.execute_reply":"2022-03-06T19:09:00.207782Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Checking for balance in label train/test sets.\nfrom collections import Counter\nCounter(y_train), Counter(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.211017Z","iopub.execute_input":"2022-03-06T19:09:00.212441Z","iopub.status.idle":"2022-03-06T19:09:00.238709Z","shell.execute_reply.started":"2022-03-06T19:09:00.212382Z","shell.execute_reply":"2022-03-06T19:09:00.238092Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Some numberization in order to apply logistic regression\n\nimport string\n\nX_train['char_count'] = X_train['headline'].apply(len)\nX_train['word_count'] = X_train['headline'].apply(lambda x: len(x.split()))\nX_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\nX_train['punctuation_count'] = X_train['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \nX_train['title_word_count'] = X_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\nX_train['upper_case_word_count'] = X_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n\n\nX_test['char_count'] = X_test['headline'].apply(len)\nX_test['word_count'] = X_test['headline'].apply(lambda x: len(x.split()))\nX_test['word_density'] = X_test['char_count'] / (X_test['word_count']+1)\nX_test['punctuation_count'] = X_test['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \nX_test['title_word_count'] = X_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\nX_test['upper_case_word_count'] = X_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.240076Z","iopub.execute_input":"2022-03-06T19:09:00.240838Z","iopub.status.idle":"2022-03-06T19:09:00.850523Z","shell.execute_reply.started":"2022-03-06T19:09:00.240801Z","shell.execute_reply":"2022-03-06T19:09:00.849624Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.852196Z","iopub.execute_input":"2022-03-06T19:09:00.852444Z","iopub.status.idle":"2022-03-06T19:09:00.865170Z","shell.execute_reply.started":"2022-03-06T19:09:00.852415Z","shell.execute_reply":"2022-03-06T19:09:00.864429Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# dropping columns with 0 from train and test features dataset.\nX_train = X_train.drop(['punctuation_count','title_word_count','upper_case_word_count'], axis=1) \nX_test = X_test.drop(['punctuation_count','title_word_count','upper_case_word_count'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.866314Z","iopub.execute_input":"2022-03-06T19:09:00.867002Z","iopub.status.idle":"2022-03-06T19:09:00.885801Z","shell.execute_reply.started":"2022-03-06T19:09:00.866962Z","shell.execute_reply":"2022-03-06T19:09:00.884798Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# importing and loading logistic regression model\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(C=1, random_state=42, solver='liblinear')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.887247Z","iopub.execute_input":"2022-03-06T19:09:00.887871Z","iopub.status.idle":"2022-03-06T19:09:00.969571Z","shell.execute_reply.started":"2022-03-06T19:09:00.887816Z","shell.execute_reply":"2022-03-06T19:09:00.968455Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# training and predicting\nlr.fit(X_train.drop(['headline'], axis=1), y_train)\npredictions = lr.predict(X_test.drop(['headline'], axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:00.971095Z","iopub.execute_input":"2022-03-06T19:09:00.971774Z","iopub.status.idle":"2022-03-06T19:09:01.043748Z","shell.execute_reply.started":"2022-03-06T19:09:00.971724Z","shell.execute_reply":"2022-03-06T19:09:01.042620Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Results with logistic regression\n\n- Precision for \"is sarcastic\" class of 57%. Precision is of all the headlines our model identified as sarcastic, 57% were correct.\n- Recall (true positive rate) of 37%. True positive rate means that from all the headlines that really were sarcastic, our\n    model could identifiy 37% of them correctly.\n    \n## with these results we see we can improve our model.","metadata":{}},{"cell_type":"code","source":"# printing results\nimport seaborn as sns\n\nprint(classification_report(y_test, predictions))\n\ncm = confusion_matrix(y_test, predictions)\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n\nlabels = [f\"{v1}\\n{v2}\" for v1, v2, in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm, annot=labels, fmt='')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:01.045587Z","iopub.execute_input":"2022-03-06T19:09:01.046676Z","iopub.status.idle":"2022-03-06T19:09:01.532863Z","shell.execute_reply.started":"2022-03-06T19:09:01.046604Z","shell.execute_reply":"2022-03-06T19:09:01.531819Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Improving the model using BOW and ensemble algorithms\n\n- This approach aims to use bag of words technique using Count Vectorizer from scikit and applying ensemble algorithms to improve precision, recall and F1-Score of our model.\n","metadata":{}},{"cell_type":"code","source":"# some cleaning on text\n\nimport nltk\nimport re\n\n# remove some stopwords to capture negation in n-grams if possible\nstop_words = nltk.corpus.stopwords.words('english')\nstop_words.remove('no')\nstop_words.remove('not')\nstop_words.remove('but')\n\n\ndef simple_text_preprocessor(document): \n    # lower case\n    document = str(document).lower()\n      \n    # remove unnecessary characters\n    document = re.sub(r'[^a-zA-Z]',r' ', document)\n    document = re.sub(r'nbsp', r'', document)\n    document = re.sub(' +', ' ', document)\n       \n    # stopwords removal\n    document = ' '.join([word for word in document.split() if word not in stop_words])\n    \n    return document\n\nstp = np.vectorize(simple_text_preprocessor)\nprint(stp)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:01.536572Z","iopub.execute_input":"2022-03-06T19:09:01.536932Z","iopub.status.idle":"2022-03-06T19:09:02.039188Z","shell.execute_reply.started":"2022-03-06T19:09:01.536896Z","shell.execute_reply":"2022-03-06T19:09:02.038275Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train['clean headline'] = stp(X_train['headline'].values)\nX_test['clean headline'] = stp(X_test['headline'].values)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:02.040468Z","iopub.execute_input":"2022-03-06T19:09:02.040763Z","iopub.status.idle":"2022-03-06T19:09:03.933450Z","shell.execute_reply.started":"2022-03-06T19:09:02.040731Z","shell.execute_reply":"2022-03-06T19:09:03.932584Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train['clean headline']","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:03.934608Z","iopub.execute_input":"2022-03-06T19:09:03.934848Z","iopub.status.idle":"2022-03-06T19:09:03.943586Z","shell.execute_reply.started":"2022-03-06T19:09:03.934810Z","shell.execute_reply":"2022-03-06T19:09:03.942562Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\nX_traincv = cv.fit_transform(X_train['clean headline']).toarray()\nX_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names_out())\n\nX_testcv = cv.transform(X_test['clean headline']).toarray()\nX_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names_out())\nX_traincv.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:03.945406Z","iopub.execute_input":"2022-03-06T19:09:03.946018Z","iopub.status.idle":"2022-03-06T19:09:06.017607Z","shell.execute_reply.started":"2022-03-06T19:09:03.945982Z","shell.execute_reply":"2022-03-06T19:09:06.016469Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"lr.fit(X_traincv, y_train)\npredictions = lr.predict(X_testcv)\n\nprint(classification_report(y_test, predictions))\npd.DataFrame(confusion_matrix(y_test, predictions))\n\ncm_lr = confusion_matrix(y_test, predictions)\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm_lr.flatten()]\n\nlabels = [f\"{v1}\\n{v2}\" for v1, v2, in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm, annot=labels, fmt='')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:06.018967Z","iopub.execute_input":"2022-03-06T19:09:06.019225Z","iopub.status.idle":"2022-03-06T19:09:15.885165Z","shell.execute_reply.started":"2022-03-06T19:09:06.019191Z","shell.execute_reply":"2022-03-06T19:09:15.884366Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Using Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nclf_MultiNB = MultinomialNB()\nclf_MultiNB.fit(X_traincv, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:15.886326Z","iopub.execute_input":"2022-03-06T19:09:15.886579Z","iopub.status.idle":"2022-03-06T19:09:48.450395Z","shell.execute_reply.started":"2022-03-06T19:09:15.886550Z","shell.execute_reply":"2022-03-06T19:09:48.449412Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"MultiNB_predictions = clf_MultiNB.predict(X_testcv)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:48.452259Z","iopub.execute_input":"2022-03-06T19:09:48.452606Z","iopub.status.idle":"2022-03-06T19:09:49.853307Z","shell.execute_reply.started":"2022-03-06T19:09:48.452559Z","shell.execute_reply":"2022-03-06T19:09:49.852280Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"MultiNB_score = clf_MultiNB.score(X_testcv, y_test)\nprint(MultiNB_score)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:49.859780Z","iopub.execute_input":"2022-03-06T19:09:49.864741Z","iopub.status.idle":"2022-03-06T19:09:51.238500Z","shell.execute_reply.started":"2022-03-06T19:09:49.864655Z","shell.execute_reply":"2022-03-06T19:09:51.237563Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, MultiNB_predictions))\ncm_NB = confusion_matrix(y_test, MultiNB_predictions)\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm_NB.flatten()]\n\nlabels = [f\"{v1}\\n{v2}\" for v1, v2, in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cm, annot=labels, fmt='')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:51.240650Z","iopub.execute_input":"2022-03-06T19:09:51.241386Z","iopub.status.idle":"2022-03-06T19:09:51.545173Z","shell.execute_reply.started":"2022-03-06T19:09:51.241334Z","shell.execute_reply":"2022-03-06T19:09:51.544391Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Predictin on test dataset with lorgistic regression algorithm\n\n    Between logistic regression and naivebayes, we found that lr performed a bit better","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/headlines-dataset/Assignment_Test_Dataset.csv')\nprint(df_test.shape) \ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:51.546474Z","iopub.execute_input":"2022-03-06T19:09:51.546726Z","iopub.status.idle":"2022-03-06T19:09:51.595893Z","shell.execute_reply.started":"2022-03-06T19:09:51.546697Z","shell.execute_reply":"2022-03-06T19:09:51.594963Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_test['clean headline'] = stp(df_test['headline'].values)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:51.597553Z","iopub.execute_input":"2022-03-06T19:09:51.598398Z","iopub.status.idle":"2022-03-06T19:09:52.040900Z","shell.execute_reply.started":"2022-03-06T19:09:51.598345Z","shell.execute_reply":"2022-03-06T19:09:52.039914Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:52.043036Z","iopub.execute_input":"2022-03-06T19:09:52.043657Z","iopub.status.idle":"2022-03-06T19:09:52.050723Z","shell.execute_reply.started":"2022-03-06T19:09:52.043606Z","shell.execute_reply":"2022-03-06T19:09:52.049844Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\nXX_testcv = cv.transform(df_test['clean headline']).toarray()\nXX_testcv = pd.DataFrame(XX_testcv, columns=cv.get_feature_names_out())\n\nXX_testcv","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:52.052277Z","iopub.execute_input":"2022-03-06T19:09:52.053140Z","iopub.status.idle":"2022-03-06T19:09:52.607372Z","shell.execute_reply.started":"2022-03-06T19:09:52.053088Z","shell.execute_reply":"2022-03-06T19:09:52.606438Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"labels = lr.predict(XX_testcv)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:09:52.608660Z","iopub.execute_input":"2022-03-06T19:09:52.608905Z","iopub.status.idle":"2022-03-06T19:09:53.993475Z","shell.execute_reply.started":"2022-03-06T19:09:52.608878Z","shell.execute_reply":"2022-03-06T19:09:53.992638Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:24:50.541306Z","iopub.execute_input":"2022-03-06T19:24:50.542157Z","iopub.status.idle":"2022-03-06T19:24:50.548037Z","shell.execute_reply.started":"2022-03-06T19:24:50.542112Z","shell.execute_reply":"2022-03-06T19:24:50.547184Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(labels).to_csv(\"/kaggle/working/predictions.csv\", header=['prediction'], index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:31:05.165696Z","iopub.execute_input":"2022-03-06T19:31:05.166024Z","iopub.status.idle":"2022-03-06T19:31:05.186419Z","shell.execute_reply.started":"2022-03-06T19:31:05.165994Z","shell.execute_reply":"2022-03-06T19:31:05.185769Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"df_predicoes = pd.read_csv('/kaggle/working/predictions.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:31:08.220924Z","iopub.execute_input":"2022-03-06T19:31:08.221214Z","iopub.status.idle":"2022-03-06T19:31:08.227682Z","shell.execute_reply.started":"2022-03-06T19:31:08.221177Z","shell.execute_reply":"2022-03-06T19:31:08.226988Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"df_predicoes.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:31:10.581776Z","iopub.execute_input":"2022-03-06T19:31:10.582300Z","iopub.status.idle":"2022-03-06T19:31:10.590947Z","shell.execute_reply.started":"2022-03-06T19:31:10.582240Z","shell.execute_reply":"2022-03-06T19:31:10.589894Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}